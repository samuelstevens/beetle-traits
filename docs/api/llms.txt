>>>> AGENTS.md
- Tensor/array variables are suffixed with _[letters], where [letters] are individual letters representing dimensions. For instance, an activation tensor `x_hat` that represents P patches, each with dimension D, would be written as `x_hat_pd`.
- Use `uv run SCRIPT.py` or `uv run python ARGS` to run python instead of Just plain `python`.
- After making edits, run `uvx ruff format --preview .` to format the file, then run `uvx ruff check --fix .` to lint, then run `uvx ty check FILEPATH` to type check (`ty` is prerelease software, and typechecking often will have false positives). Only do this if you think you're finished, or if you can't figure out a bug. Maybe linting will make it obvious. Don't fix linting or typing errors in files you haven't modified.
- Prefer negative if statements in combination with early returns/continues. Rather than nesting multiple positive if statements, just check if a condition is False, then return/continue in a loop. This reduces indentation.
- This project uses Python 3.12. You can use `dict`, `list`, `tuple` instead of the imports from `typing`. You can use `| None` instead of `Optional`.
- This project decorates functions and classes with `@beartype.beartype` to do run-time checking of types. If a function is extremely simple, don't worry about it.

>>>> README.md
# Beetle Traits

This repo annotates beetle elytra widths and lengths from top-down specimen images of beetles.

## Data

https://huggingface.co/datasets/imageomics/2018-NEON-beetles

https://huggingface.co/datasets/imageomics/Hawaii-beetles

uv run src/btx/scripts/format_hawaii.py --ignore-errors --sample-rate 5 --hf-root /fs/scratch/PAS2136/samuelstevens/datasets/hawaii-beetles/ --slurm-acct PAS2136 --slurm-partition nextgen --n-hours 4

## Modeling

>>>> __init__.py


>>>> data/__init__.py
from .beetlepalooza import Config as BeetlePaloozaConfig
from .beetlepalooza import Dataset as BeetlePaloozaDataset
from .biorepo import Config as BioRepoConfig
from .biorepo import Dataset as BioRepoDataset
from .hawaii import Config as HawaiiConfig
from .hawaii import Dataset as HawaiiDataset

__all__ = [
    "BioRepoConfig",
    "BioRepoDataset",
    "HawaiiConfig",
    "HawaiiDataset",
    "BeetlePaloozaConfig",
    "BeetlePaloozaDataset",
]

>>>> data/beetlepalooza.py
class Config:
    pass


class Dataset:
    pass

>>>> data/biorepo.py
class Config:
    pass


class Dataset:
    pass

>>>> data/hawaii.py
"""Hawaii beetle dataset loader for trait prediction model training.

Goal:
Load individual beetle images with their trait annotations (elytra max length,
basal pronotum width, elytra max width) for training keypoint detection models.
Each sample should contain an individual beetle image cropped from the group
photo and the corresponding trait polylines in pixel coordinates.

Dataset Structure:
- annotations.json: Contains all beetle annotations with:
  - Individual image paths (relative to HuggingFace dataset root)
  - Origin coordinates (x, y) in the group image
  - Trait measurements as polylines in individual image coordinates
  - NCC score from template matching (confidence metric)
- Individual images: Located at HF_ROOT/individual_specimens/
- Group images: Located at HF_ROOT/group_images/ (not needed for training)

Implementation Challenges:

1. Path resolution:
   - Annotations contain absolute paths that need conversion to relative
   - Must handle both local and scratch filesystem paths
   Solution: Extract relative path components from indiv_img_rel_path field

2. Coordinate systems:
   - Polylines are already in individual image pixel coordinates
   - No transformation needed, just validation
   Solution: Directly use polyline_px coordinates from annotations

3. Data filtering:
   - Some beetles may have missing or incomplete annotations
   - NCC scores indicate template matching confidence
   Solution: Filter by NCC threshold (e.g., > 0.8) and validate all traits present

4. Memory efficiency:
   - Dataset has ~1600 beetles, loading all at once may be excessive
   - Images vary in size (typically 400-1000px per dimension)
   Solution: Use grain's lazy loading, load images on-demand in __getitem__

Unresolved Challenges:
- Handling variable image sizes for batch training (requires padding/resizing)
- Dealing with outlier beetle sizes (some are 1500+ pixels)
- Normalizing trait measurements across different beetle scales
- Variable keypoint counts: elytra_max_width has 2 points (73%) or 4 points (27%)
  when wings are spread. With 4 points, only outer segments matter (middle segment
  crosses the gap between wings). Models need fixed keypoint counts, so options:
  a) Always predict 4 points, ignore middle segment when present
  b) Only predict 2 endpoints, but this overestimates width for spread wings
  c) Predict wing spread as separate classification task, then variable points

Testing Strategy:
1. Load a few samples and visualize with trait polylines overlaid
2. Verify polyline coordinates fall within image bounds
3. Check distribution of NCC scores and image dimensions
4. Test with grain's DataLoader for batching compatibility
5. Validate against saved example images in random-examples/
"""

import dataclasses
import logging
import pathlib
import typing as tp

import beartype
import grain
import numpy as np
import polars as pl

from . import utils

logger = logging.getLogger("hawaii")


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    hf_root: pathlib.Path = pathlib.Path("data/hawaii")
    """Path to the dataset root downloaded from HuggingFace."""
    annotations: pathlib.Path = pathlib.Path("data/hawaii-formatted/annotations.json")
    """Path to the annotations.json file made by running format_hawaii.py."""
    include_polylines: bool = True
    """Whether to include polylines (lines with more than 2 points)."""
    split: tp.Literal["train", "val"] = "train"
    """Which split."""
    # Split-related configuration.
    seed: int = 0
    """Random seed for split."""
    min_val_groups: int = 2
    """Minimum group images per species in validation."""
    min_val_beetles: int = 20
    """Minimum beetles per species in validation."""

    def __post_init__(self):
        # TODO: Check that hf_root exists and is a directory
        # TODO: Check that annotations.json exists and is a file.
        pass


@beartype.beartype
def _grouped_split(cfg: Config) -> pl.DataFrame:
    """
    Group-aware train/val split.

    For each species, try to grab at least two group images and 10 samples per species. All of the individuals in a single group image are either in train OR test.
    """
    df = pl.read_json(cfg.annotations)

    # Create group-level statistics dataframe
    group_stats = df.group_by(["group_img_basename", "taxon_id"]).agg(
        pl.len().alias("n_beetles")
    )

    # Add taxon-level group counts
    taxon_group_counts = group_stats.group_by("taxon_id").agg(
        pl.col("group_img_basename").n_unique().alias("n_groups")
    )

    # Join to get n_groups for each row
    group_stats = group_stats.join(taxon_group_counts, on="taxon_id")

    # Species with limited group images go ENTIRELY to validation
    val_group_imgs = set()
    val_group_imgs.update(
        group_stats.filter(pl.col("n_groups") <= cfg.min_val_groups)
        .get_column("group_img_basename")
        .to_list()
    )

    # For species with more groups, select up to cfg.min_val_groups groups and 10 samples
    for (taxon_id,) in (
        taxon_group_counts.filter(pl.col("n_groups") > cfg.min_val_groups)
        .select("taxon_id")
        .iter_rows()
    ):
        taxon_groups = group_stats.filter(pl.col("taxon_id") == taxon_id).filter(
            ~pl.col("group_img_basename").is_in(val_group_imgs)
        )

        # Take groups until we have 2 groups or 10 samples
        total_beetles = 0
        total_groups = 0
        for group_img, n_beetles in (
            taxon_groups.select("group_img_basename", "n_beetles")
            .sample(fraction=1.0, with_replacement=False, shuffle=True, seed=cfg.seed)
            .iter_rows()
        ):
            if (
                total_groups >= cfg.min_val_groups
                and total_beetles >= cfg.min_val_beetles
            ):
                break

            val_group_imgs.add(group_img)
            total_beetles += n_beetles
            total_groups += 1

    # Log the split statistics
    total = len(df)
    val_df = df.filter(pl.col("group_img_basename").is_in(val_group_imgs))
    val_total = len(val_df)

    # Get per-taxon statistics
    val_stats = val_df.group_by("taxon_id").agg([
        pl.len().alias("val_samples"),
        pl.col("group_img_basename").n_unique().alias("val_groups"),
    ])

    # Join with totals
    taxon_totals = df.group_by("taxon_id").agg([
        pl.len().alias("total_samples"),
        pl.col("group_img_basename").n_unique().alias("total_groups"),
    ])

    split_stats = taxon_totals.join(val_stats, on="taxon_id", how="left").fill_null(0)

    logger.info(
        f"Total samples: {total}, Val: {val_total} ({100 * val_total / total:.1f}%)"
    )

    for row in split_stats.sort("taxon_id").iter_rows(named=True):
        taxon_id = row["taxon_id"]
        total_count = row["total_samples"]
        val_count = row["val_samples"]
        total_groups = row["total_groups"]
        val_groups_count = row["val_groups"]

        split_type = "ALL VAL" if total_groups <= 2 else "MIXED"
        pct = 100 * val_count / total_count if total_count > 0 else 0
        logger.info(
            f"  {taxon_id} [{split_type}]: {val_count}/{total_count} samples ({pct:.1f}%), "
            f"{val_groups_count}/{total_groups} groups"
        )

    # Build split table (each beetle inherits its group's split)
    return df.with_columns(
        pl.when(pl.col("group_img_basename").is_in(val_group_imgs))
        .then(pl.lit("val"))
        .otherwise(pl.lit("train"))
        .alias("split")
    )


@beartype.beartype
class Dataset(grain.sources.RandomAccessDataSource):
    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.df = _grouped_split(cfg).filter(pl.col("split") == cfg.split)

        self.logger = logging.getLogger("hawaii-ds")

        if self.cfg.include_polylines:
            raise NotImplementedError()
        else:
            # measurements: list[struct[2]]
            # Example:
            # [{'measurement_type': 'elytra_max_length', 'polyline_px': [231.3699999999999, 410.8299999999999, 190.32999999999993, 239.17999999999984]}, {'measurement_type': 'basal_pronotum_width', 'polyline_px': [187.57999999999993, 237.21000000000004, 250.0300000000002, 216.0]}, {'measurement_type': 'elytra_max_width', 'polyline_px': [178.92999999999984, 341.8899999999999, 293.03999999999996, 316.3600000000001]}]
            #
            # Only pick examples where all measurements only have four floats (two points)
            self.df = self.df.filter(
                pl.col("measurements").map_elements(
                    lambda measurements: all(
                        len(m["polyline_px"]) == 4 for m in measurements
                    ),
                    return_dtype=pl.Boolean,
                )
            )

    def __len__(self) -> int:
        return self.df.height

    def __getitem__(self, idx: int) -> utils.Sample:
        """Load image and annotations for given index."""
        row = self.df.row(index=idx, named=True)
        fpath = self.cfg.hf_root / "individual_specimens" / row["indiv_img_rel_path"]
        # TODO: include error message.
        assert fpath.is_file()

        elytra_width_px = None
        elytra_length_px = None
        for measurement in row["measurements"]:
            if measurement["measurement_type"] == "elytra_max_length":
                elytra_length_px = measurement["polyline_px"]
            if measurement["measurement_type"] == "elytra_max_width":
                elytra_width_px = measurement["polyline_px"]

        if elytra_width_px is None:
            self.logger.error(
                "Image %s beetle %d has no elytra width.",
                row["group_img_rel_path"],
                row["beetle_position"],
            )
            elytra_width_px = [0.0, 0.0, 0.0, 0.0]
        if elytra_length_px is None:
            self.logger.error(
                "Image %s beetle %d has no elytra length.",
                row["group_img_rel_path"],
                row["beetle_position"],
            )
            elytra_length_px = [0.0, 0.0, 0.0, 0.0]

        if self.cfg.include_polylines:
            raise NotImplementedError()

        return utils.Sample(
            img_fpath=str(fpath),
            points_px=np.array(elytra_width_px + elytra_length_px).reshape(2, 2, 2),
            beetle_id=row["individual_id"],
            beetle_position=row["beetle_position"],
            group_img_basename=row["group_img_basename"],
        )

>>>> data/utils.py
import dataclasses
import typing as tp

import beartype
import grain
import numpy as np
from jaxtyping import Float, jaxtyped
from PIL import Image


@jaxtyped(typechecker=beartype.beartype)
class Sample(tp.TypedDict):
    img_fpath: str

    points_px: Float[np.ndarray, "2 2 2"]
    """{width, length} x two points x {x, y}."""

    # Metadata
    beetle_id: str
    beetle_position: int
    group_img_basename: str


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class DecodeRGB(grain.transforms.Map):
    def map(self, sample: Sample) -> Sample:
        # Heavy I/O lives in a transform so workers can parallelize it
        with Image.open(sample["img_fpath"]) as im:
            sample["img"] = im.convert("RGB")
        return sample


@dataclasses.dataclass(frozen=True)
class Resize(grain.transforms.Map):
    size: int = 256

    def map(self, sample: dict[str, object]) -> dict[str, object]:
        img = sample["img"]
        orig_h, orig_w = img.size

        img = np.array(img.resize((self.size, self.size)))
        sample["img"] = img.astype(np.float32) / 255.0

        # Rescale the measurements according to the new size
        scale_x = self.size / orig_w
        scale_y = self.size / orig_h

        points = sample["points_px"].copy()
        points[:, :, 0] *= scale_x
        points[:, :, 1] *= scale_y
        sample["tgt"] = points

        sample["scale"] = np.array([scale_x, scale_y])

        return sample

>>>> helpers.py
# src/btx/helpers.py
import collections.abc
import logging
import pathlib
import re
import subprocess
import time

import beartype


@beartype.beartype
def fssafe(s: str) -> str:
    """
    Convert a string to be filesystem-safe by replacing special characters.

    This is particularly useful for checkpoint names that contain characters like
    'hf-hub:timm/ViT-L-16-SigLIP2-256' which need to be converted to something like
    'hf-hub_timm_ViT-L-16-SigLIP2-256'.

    Args:
        s: String to make filesystem-safe.

    Returns:
        Filesystem-safe version of the string.
    """
    # Replace common problematic characters with underscores
    replacements = {
        "/": "_",
        "\\": "_",
        ":": "_",
        "*": "_",
        "?": "_",
        '"': "_",
        "<": "_",
        ">": "_",
        "|": "_",
        " ": "_",
    }
    for old, new in replacements.items():
        s = s.replace(old, new)
    # Remove any remaining non-alphanumeric characters except - _ .
    return "".join(c if c.isalnum() or c in "-_." else "_" for c in s)


@beartype.beartype
class progress:
    def __init__(self, it, *, every: int = 10, desc: str = "progress", total: int = 0):
        """
        Wraps an iterable with a logger like tqdm but doesn't use any control codes to manipulate a progress bar, which doesn't work well when your output is redirected to a file. Instead, simple logging statements are used, but it includes quality-of-life features like iteration speed and predicted time to finish.

        Args:
            it: Iterable to wrap.
            every: How many iterations between logging progress.
            desc: What to name the logger.
            total: If non-zero, how long the iterable is.
        """
        self.it = it
        self.every = max(1, every)
        self.logger = logging.getLogger(desc)
        self.total = total

    def __iter__(self):
        start = time.time()

        try:
            total = len(self)
        except TypeError:
            total = None

        for i, obj in enumerate(self.it):
            yield obj

            if (i + 1) % self.every == 0:
                now = time.time()
                duration_s = now - start
                per_min = (i + 1) / (duration_s / 60)

                if total is not None:
                    pred_min = (total - (i + 1)) / per_min
                    self.logger.info(
                        "%d/%d (%.1f%%) | %.1f it/m (expected finish in %.1fm)",
                        i + 1,
                        total,
                        (i + 1) / total * 100,
                        per_min,
                        pred_min,
                    )
                else:
                    self.logger.info("%d/? | %.1f it/m", i + 1, per_min)

    def __len__(self) -> int:
        if self.total > 0:
            return self.total

        # Will throw exception.
        return len(self.it)


@beartype.beartype
class batched_idx:
    """
    Iterate over (start, end) indices for total_size examples, where end - start is at most batch_size.

    Args:
        total_size: total number of examples
        batch_size: maximum distance between the generated indices.

    Returns:
        A generator of (int, int) tuples that can slice up a list or a tensor.
    """

    def __init__(self, total_size: int, batch_size: int):
        """
        Args:
            total_size: total number of examples
            batch_size: maximum distance between the generated indices
        """
        self.total_size = total_size
        self.batch_size = batch_size

    def __iter__(self) -> collections.abc.Iterator[tuple[int, int]]:
        """Yield (start, end) index pairs for batching."""
        for start in range(0, self.total_size, self.batch_size):
            stop = min(start + self.batch_size, self.total_size)
            yield start, stop

    def __len__(self) -> int:
        """Return the number of batches."""
        return (self.total_size + self.batch_size - 1) // self.batch_size


@beartype.beartype
def current_git_commit() -> str | None:
    """
    Best-effort short SHA of the repo containing *this* file.

    Returns `None` when
    * `git` executable is missing,
    * weâ€™re not inside a git repo (e.g. installed wheel),
    * or any git call errors out.
    """
    try:
        # Walk up until we either hit a .git dir or the FS root
        here = pathlib.Path(__file__).resolve()
        for parent in (here, *here.parents):
            if (parent / ".git").exists():
                break
        else:  # no .git found
            return None

        result = subprocess.run(
            ["git", "-C", str(parent), "rev-parse", "--short", "HEAD"],
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
            check=True,
        )
        return result.stdout.strip() or None
    except (FileNotFoundError, subprocess.CalledProcessError):
        return None


@beartype.beartype
def get_slurm_max_array_size() -> int:
    """
    Get the MaxArraySize configuration from the current Slurm cluster.

    Returns:
        int: The maximum array size allowed on the cluster. Returns 1000 as fallback if unable to determine.
    """
    logger = logging.getLogger("helpers.slurm")
    try:
        # Run scontrol command to get config information
        result = subprocess.run(
            ["scontrol", "show", "config"], capture_output=True, text=True, check=True
        )

        # Search for MaxArraySize in the output
        match = re.search(r"MaxArraySize\s*=\s*(\d+)", result.stdout)
        if match:
            max_array_size = int(match.group(1))
            logger.info("Detected MaxArraySize = %d", max_array_size)
            return max_array_size
        else:
            logger.warning(
                "Could not find MaxArraySize in scontrol output, using default of 1000"
            )
            return 1000

    except subprocess.SubprocessError as e:
        logger.error("Error running scontrol: %s", e)
        return 1000  # Safe default
    except ValueError as e:
        logger.error("Error parsing MaxArraySize: %s", e)
        return 1000  # Safe default
    except FileNotFoundError:
        logger.warning(
            "scontrol command not found. Assuming not in Slurm environment. Returning default MaxArraySize=1000."
        )
        return 1000


@beartype.beartype
def get_slurm_max_submit_jobs() -> int:
    """
    Get the MaxSubmitJobs limit from the current user's QOS.

    Returns:
        int: The maximum number of jobs that can be submitted at once. Returns 1000 as fallback.
    """
    logger = logging.getLogger("helpers.slurm")
    try:
        # First, try to get the QOS from a recent job
        result = subprocess.run(
            ["scontrol", "show", "job", "-o"],
            capture_output=True,
            text=True,
            check=False,
        )

        qos_name = None
        if result.returncode == 0 and result.stdout:
            # Extract QOS from job info
            match = re.search(r"QOS=(\S+)", result.stdout)
            if match:
                qos_name = match.group(1)

        if not qos_name:
            # If no jobs, try to get default QOS from association
            # This is less reliable but better than nothing
            logger.warning("No active jobs to determine QOS, using default of 1000")
            return 1000

        # Get the MaxSubmitJobs for this QOS
        result = subprocess.run(
            ["sacctmgr", "show", "qos", qos_name, "format=maxsubmitjobs", "-n", "-P"],
            capture_output=True,
            text=True,
            check=True,
        )

        max_submit = result.stdout.strip()
        if max_submit and max_submit.isdigit():
            limit = int(max_submit)
            logger.info("Detected MaxSubmitJobs = %d for QOS %s", limit, qos_name)
            return limit
        else:
            logger.warning("Could not parse MaxSubmitJobs, using default of 1000")
            return 1000

    except subprocess.SubprocessError as e:
        logger.error("Error getting MaxSubmitJobs: %s", e)
        return 1000
    except (ValueError, FileNotFoundError) as e:
        logger.error("Error: %s", e)
        return 1000


@beartype.beartype
def get_slurm_job_count() -> int:
    """
    Get the current number of jobs in the queue for the current user.

    Uses squeue's -r flag to properly count job array elements individually.
    For example, a job array 12345_[0-99] will be counted as 100 jobs.
    """
    try:
        # Use -r to display each array element on its own line
        result = subprocess.run(
            ["squeue", "--me", "-h", "-r"], capture_output=True, text=True, check=True
        )

        # Count non-empty lines
        lines = result.stdout.strip().split("\n")
        return len([line for line in lines if line.strip()])

    except (subprocess.SubprocessError, FileNotFoundError):
        # If we can't check, assume no jobs
        return 0

>>>> modeling/__init__.py
import typing as tp

import beartype
import chex
import equinox as eqx

from . import toy

Config = toy.Config


@beartype.beartype
def make(cfg: Config, key: chex.PRNGKey) -> eqx.Module:
    if isinstance(cfg, toy.Config):
        return toy.Model(cfg, key=key)
    else:
        tp.assert_never(cfg)

>>>> modeling/dinov3.py
# /src/btx/modeling/dinov3.py
import dataclasses
import functools
import json
import math
import pathlib
import typing as tp
from collections.abc import Callable

import beartype
import chex
import einops
import equinox as eqx
import jax
import jax.numpy as jnp
import numpy as np
from jaxtyping import Array, Float, PyTree, jaxtyped


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    img_size: int = 224
    patch_size: int = 16
    in_chans: int = 3
    pos_embed_rope_base: float = 100.0
    pos_embed_rope_min_period: float | None = None
    pos_embed_rope_max_period: float | None = None
    pos_embed_rope_normalize_coords: tp.Literal["min", "max", "separate"] = "separate"
    pos_embed_rope_shift_coords: float | None = None
    pos_embed_rope_jitter_coords: float | None = None
    pos_embed_rope_rescale_coords: float | None = None
    pos_embed_rope_dtype: str = "bf16"
    embed_dim: int = 768
    depth: int = 12
    num_heads: int = 12
    ffn_ratio: float = 4.0
    qkv_bias: bool = True
    drop_path_rate: float = 0.0
    layerscale_init: float | None = None
    norm_layer: str = "layernorm"
    ffn_layer: str = "mlp"
    ffn_bias: bool = True
    proj_bias: bool = True
    n_storage_tokens: int = 0
    mask_k_bias: bool = False
    untie_cls_and_patch_norms: bool = False
    untie_global_and_local_cls_norm: bool = False
    device: tp.Any | None = None


_norm_layer_lookup = {
    "layernorm": functools.partial(eqx.nn.LayerNorm, eps=1e-6),
    "layernormbf16": functools.partial(eqx.nn.LayerNorm, eps=1e-5),
}

_dtype_lookup = {
    "fp32": jnp.dtype("float32"),
}

_act_fn_lookup = {"gelu": functools.partial(jax.nn.gelu, approximate=False)}


@jaxtyped(typechecker=beartype.beartype)
def rope_rotate_half(
    x_hnd: Float[Array, "n_heads n d_head"],
) -> Float[Array, "n_heads n d_head"]:
    # x:   [ x0  x1  x2  x3  x4  x5]
    # out: [-x3 -x4 -x5  x0  x1  x2]
    x1, x2 = jnp.split(x_hnd, 2, axis=-1)
    return jnp.concatenate((-x2, x1), axis=-1)


@jaxtyped(typechecker=beartype.beartype)
def apply_rope(
    x: Float[Array, "n_heads n d_head"],
    sin: Float[Array, "n d_head"],
    cos: Float[Array, "n d_head"],
) -> Float[Array, "n_heads n d_head"]:
    # x:   [..., D], eg [x0,     x1,   x2,   x3,   x4,   x5]
    # sin: [..., D], eg [sin0, sin1, sin2, sin0, sin1, sin2]
    # cos: [..., D], eg [cos0, cos1, cos2, cos0, cos1, cos2]
    return (x * cos) + (rope_rotate_half(x) * sin)


@jaxtyped(typechecker=beartype.beartype)
def rope_fn(
    q_nhd: Float[Array, "n n_heads d_head"],
    k_nhd: Float[Array, "n n_heads d_head"],
    rope_2pd: Float[Array, "2 n_pos d_head"],
) -> tuple[Float[Array, "n n_heads d_head"], Float[Array, "n n_heads d_head"]]:
    sin_pd, cos_pd = rope_2pd

    n, n_heads, d_head = q_nhd.shape
    n_pos, d_head = sin_pd.shape

    prefix = n - n_pos
    assert prefix >= 0, f"Got {n} residual streams but only {n_pos} patches."

    q_prefix_hd = q_nhd[:prefix]
    q_hpd = einops.rearrange(
        q_nhd[prefix:], "n_pos n_heads d_head -> n_heads n_pos d_head"
    )
    q_phd = einops.rearrange(
        apply_rope(q_hpd, sin_pd, cos_pd),
        "n_heads n_pos d_head -> n_pos n_heads d_head",
    )
    q_nhd = jnp.concatenate((q_prefix_hd, q_phd), axis=0)
    k_prefix_hd = k_nhd[:prefix]
    k_hpd = einops.rearrange(
        k_nhd[prefix:], "n_pos n_heads d_head -> n_heads n_pos d_head"
    )
    k_phd = einops.rearrange(
        apply_rope(k_hpd, sin_pd, cos_pd),
        "n_heads n_pos d_head -> n_pos n_heads d_head",
    )
    k_nhd = jnp.concatenate((k_prefix_hd, k_phd), axis=0)
    return q_nhd, k_nhd


@jaxtyped(typechecker=beartype.beartype)
class PatchEmbed(eqx.Module):
    """
    2D image to patch embedding: (C,H,W) -> (N,D)

    Args:
        img_size: Image size.
        patch_size: Patch token size.
        in_chans: Number of input image channels.
        embed_dim: Number of linear projection output channels.
    """

    img_size: tuple[int, int]
    patch_size: tuple[int, int]
    num_patches: int
    in_chans: int
    embed_dim: int
    proj: eqx.nn.Conv2d

    def __init__(
        self,
        img_size: int,
        patch_size: int,
        in_chans: int,
        embed_dim: int,
        key: chex.PRNGKey,
    ) -> None:
        image_HW = (img_size, img_size)
        patch_HW = (patch_size, patch_size)
        patch_grid_size = (image_HW[0] // patch_HW[0], image_HW[1] // patch_HW[1])

        self.img_size = image_HW
        self.patch_size = patch_HW
        self.num_patches = patch_grid_size[0] * patch_grid_size[1]

        self.in_chans = in_chans
        self.embed_dim = embed_dim

        self.proj = eqx.nn.Conv2d(
            in_chans, embed_dim, kernel_size=patch_HW, stride=patch_HW, key=key
        )

    def __call__(
        self, x_chw: Float[Array, "channnels height width"]
    ) -> Float[Array, "n dim"]:
        _, H, W = x_chw.shape
        # patch_H, patch_W = self.patch_size
        # assert H % patch_H == 0, f"Input image height {H} is not a multiple of patch height {patch_H}"
        # assert W % patch_W == 0, f"Input image width {W} is not a multiple of patch width: {patch_W}"

        x_dhw = self.proj(x_chw)
        _, h, w = x_dhw.shape
        x_nd = einops.rearrange(x_dhw, "d h w -> (h w) d")
        x = einops.rearrange(x_nd, "(h w) d -> h w d", h=h, w=h)
        return x


@jaxtyped(typechecker=beartype.beartype)
class LayerScale(eqx.Module):
    gamma: Float[Array, " dim"]

    def __init__(self, dim: int, *, key: chex.PRNGKey):
        # TODO: initialize with key
        self.gamma = jnp.zeros(dim)

    def __call__(self, x: Float[Array, "..."]) -> Float[Array, "..."]:
        return x * self.gamma


@jaxtyped(typechecker=beartype.beartype)
class RopePositionEmbedding(eqx.Module):
    """RoPE positional embedding with no mixing of coordinates (axial) and no learnable weights. Supports two parametrizations of the rope parameters: either using `base` or `min_period` and `max_period`."""

    d_head: int
    base: float | None
    min_period: float | None
    max_period: float | None
    normalize_coords: tp.Literal["min", "max", "separate"]
    dtype: jnp.dtype

    periods: Float[Array, " d_period"]

    def __init__(
        self,
        embed_dim: int,
        *,
        num_heads: int,
        base: float | None,
        min_period: float | None,
        max_period: float | None,
        normalize_coords: tp.Literal["min", "max", "separate"],
        dtype: jnp.dtype,
    ):
        assert embed_dim % (4 * num_heads) == 0
        both_periods = min_period is not None and max_period is not None
        if (base is None and not both_periods) or (base is not None and both_periods):
            raise ValueError(
                "Either `base` or `min_period`+`max_period` must be provided."
            )

        self.base = base
        self.min_period = min_period
        self.max_period = max_period
        self.d_head = embed_dim // num_heads
        self.normalize_coords = normalize_coords
        self.dtype = dtype

        if self.base is not None:
            periods = self.base ** (
                2 * jnp.arange(self.d_head // 4, dtype=dtype) / (self.d_head // 2)
            )
        else:
            base = self.max_period / self.min_period
            exponents = jnp.linspace(0, 1, self.d_head // 4, dtype=dtype)
            periods = base**exponents  # range [1, max_period / min_period]
            periods = periods / base  # range [min_period / max_period, 1]
            periods = periods * self.max_period  # range [min_period, max_period]

        self.periods = periods

    def __call__(
        self, *, h: int, w: int
    ) -> tuple[Float[Array, "{h*w} d_head"], Float[Array, "{h*w} d_head"]]:
        # Prepare coords in range [-1, +1]
        if self.normalize_coords == "max":
            max_hw = max(h, w)
            coords_h = jnp.arange(0.5, h, dtype=self.dtype) / max_hw  # [H]
            coords_w = jnp.arange(0.5, w, dtype=self.dtype) / max_hw  # [W]
        elif self.normalize_coords == "min":
            min_hw = min(h, w)
            coords_h = jnp.arange(0.5, h, dtype=self.dtype) / min_hw  # [H]
            coords_w = jnp.arange(0.5, w, dtype=self.dtype) / min_hw  # [W]
        elif self.normalize_coords == "separate":
            coords_h = jnp.arange(0.5, h, dtype=self.dtype) / h  # [H]
            coords_w = jnp.arange(0.5, w, dtype=self.dtype) / w  # [W]
        else:
            raise ValueError(f"Unknown normalize_coords: {self.normalize_coords}")

        coords_hw2 = jnp.stack(jnp.meshgrid(coords_h, coords_w, indexing="ij"), axis=-1)
        coords_n2 = einops.rearrange(
            coords_hw2, "height width ndim -> (height width) ndim"
        )
        coords_n2 = 2.0 * coords_n2 - 1.0  # Shift range [0, 1] to [-1, +1]

        # Prepare angles and sin/cos
        angles = (
            2 * math.pi * coords_n2[:, :, None] / self.periods[None, None, :]
        )  # [HW, 2, D//4]
        angles = einops.rearrange(
            angles, "n ndim subhead -> n (ndim subhead)"
        )  # [HW, D//2]
        angles = jnp.tile(angles, (1, 2))  # [HW, D]
        cos = jnp.cos(angles)  # [HW, D]
        sin = jnp.sin(angles)  # [HW, D]

        return (sin, cos)  # 2 * [HW, D]


@beartype.beartype
class LinearKMaskedBias(eqx.nn.Linear):
    bias_mask: Float[Array, " d_out"] | None

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        assert self.out_features % 3 == 0

        if self.bias is not None:
            # This is a bug: https://github.com/facebookresearch/dinov3/issues/58#issuecomment-3204669831. But since it doesn't affect the released models (they all have 0 in their bias_mask), we don't worry about it.
            self.bias_mask = jnp.zeros_like(self.bias)

    def forward(self, x: Float[Array, " d_in"]) -> Float[Array, " d_out"]:
        x = self.weight @ x
        if self.bias is not None:
            masked_bias = self.bias * self.bias_mask.to(self.bias.dtype)
            x = x + masked_bias
        return x


@beartype.beartype
class Mlp(eqx.Module):
    in_features: int
    hidden_features: int
    out_features: int
    fc1: eqx.nn.Linear
    act: Callable
    fc2: eqx.nn.Linear

    def __init__(
        self,
        in_features: int,
        hidden_features: int | None,
        out_features: int | None,
        act_fn: str,
        *,
        key: chex.PRNGKey,
    ):
        self.in_features = in_features
        self.hidden_features = hidden_features or in_features
        self.out_features = out_features or in_features

        k1, k2 = jax.random.split(key, 2)
        self.fc1 = eqx.nn.Linear(
            self.in_features, self.hidden_features, use_bias=True, key=k1
        )
        self.fc2 = eqx.nn.Linear(
            self.hidden_features, self.in_features, use_bias=True, key=k2
        )
        self.act = _act_fn_lookup[act_fn]

    def __call__(self, x: Float[Array, " d"]) -> Float[Array, " d"]:
        x = self.fc1(x)
        x = self.act(x)
        x = self.fc2(x)
        return x


@beartype.beartype
class SelfAttention(eqx.Module):
    cfg: Config
    scale: float
    qkv: eqx.nn.Linear | LinearKMaskedBias
    proj: eqx.nn.Linear

    def __init__(self, cfg: Config, *, key: chex.PRNGKey):
        self.cfg = cfg
        head_dim = cfg.embed_dim // cfg.num_heads
        self.scale = head_dim**-0.5

        k1, k2 = jax.random.split(key, 2)

        linear_class = LinearKMaskedBias if cfg.mask_k_bias else eqx.nn.Linear
        self.qkv = linear_class(
            cfg.embed_dim, cfg.embed_dim * 3, use_bias=cfg.qkv_bias, key=k1
        )
        self.proj = eqx.nn.Linear(
            cfg.embed_dim, cfg.embed_dim, use_bias=cfg.proj_bias, key=k2
        )

    def __call__(
        self, x_nd: Float[Array, "n_tok d"], rope: Float[Array, "2 n_pos d_head"] | None
    ) -> Float[Array, "n d"]:
        n_tok, d = x_nd.shape

        qkv_3nd = einops.rearrange(
            jax.vmap(self.qkv)(x_nd),
            "n_tok (parts d) -> parts n_tok d",
            parts=3,  # [q, k, v] = 3 parts
            d=d,
        )
        qkv_3nhd = einops.rearrange(
            qkv_3nd,
            "parts n_tok (n_heads d_head) -> parts n_tok n_heads d_head",
            parts=3,
            n_heads=self.cfg.num_heads,
            d_head=d // self.cfg.num_heads,
        )
        q_nhd, k_nhd, v_nhd = jnp.unstack(qkv_3nhd, axis=0)
        if rope is not None:
            q_nhd, k_nhd = rope_fn(q_nhd, k_nhd, rope)
        x_nhd = jax.nn.dot_product_attention(q_nhd, k_nhd, v_nhd)

        x_nd = einops.rearrange(x_nhd, "n_tok n_heads d_head -> n_tok (n_heads d_head)")
        x_nd = jax.vmap(self.proj)(x_nd)
        return x_nd


@beartype.beartype
class SelfAttentionBlock(eqx.Module):
    cfg: Config
    ls1: LayerScale
    norm1: eqx.Module
    norm2: eqx.Module
    attn: SelfAttention
    mlp: Mlp
    ls2: LayerScale

    def __init__(self, cfg: Config, key: chex.PRNGKey):
        self.cfg = cfg
        k1, k2, k3, k4 = jax.random.split(key, 4)
        self.ls1 = LayerScale(cfg.embed_dim, key=k1)
        self.norm1 = _norm_layer_lookup[cfg.norm_layer](cfg.embed_dim)
        self.norm2 = _norm_layer_lookup[cfg.norm_layer](cfg.embed_dim)
        self.attn = SelfAttention(cfg, key=k2)
        ffn_hidden_dim = int(cfg.embed_dim * cfg.ffn_ratio)
        self.mlp = Mlp(cfg.embed_dim, ffn_hidden_dim, cfg.embed_dim, "gelu", key=k3)
        self.ls2 = LayerScale(cfg.embed_dim, key=k4)

    def __call__(
        self, x_nd: Float[Array, "n d"], rope: Float[Array, "2 n d_head"]
    ) -> Float[Array, "n d"]:
        x_attn_nd = x_nd + self.ls1(self.attn(jax.vmap(self.norm1)(x_nd), rope=rope))
        x_ffn_nd = x_attn_nd + self.ls2(
            jax.vmap(self.mlp)(jax.vmap(self.norm2)(x_attn_nd))
        )
        return x_ffn_nd


@beartype.beartype
class VisionTransformer(eqx.Module):
    cfg: Config
    cls_token: Float[Array, " dim"]
    storage_tokens: Float[Array, "n_storage dim"]
    mask_token: Float[Array, " dim"]
    patch_embed: PatchEmbed
    rope_embed: RopePositionEmbedding
    blocks: list[SelfAttentionBlock]
    norm: eqx.Module

    def __init__(self, cfg: Config, key: chex.PRNGKey):
        self.cfg = cfg

        assert not self.cfg.untie_cls_and_patch_norms, "Not supported"

        k1, *keys = jax.random.split(key, (2 + cfg.depth))

        self.cls_token = jnp.zeros((cfg.embed_dim,))
        self.storage_tokens = jnp.zeros((cfg.n_storage_tokens, cfg.embed_dim))
        self.mask_token = jnp.zeros((cfg.embed_dim,))

        self.patch_embed = PatchEmbed(
            cfg.img_size,
            cfg.patch_size,
            cfg.in_chans,
            cfg.embed_dim,
            k1,
        )
        self.rope_embed = RopePositionEmbedding(
            cfg.embed_dim,
            num_heads=cfg.num_heads,
            base=cfg.pos_embed_rope_base,
            min_period=cfg.pos_embed_rope_min_period,
            max_period=cfg.pos_embed_rope_max_period,
            normalize_coords=cfg.pos_embed_rope_normalize_coords,
            dtype=_dtype_lookup[cfg.pos_embed_rope_dtype],
        )
        self.blocks = [SelfAttentionBlock(cfg, k) for k in keys]
        self.norm = _norm_layer_lookup[cfg.norm_layer](cfg.embed_dim)

    def __call__(self, x: Float[Array, "..."]):
        x_hwd = self.patch_embed(x)
        h, w, _ = x_hwd.shape
        x_nd = einops.rearrange(x_hwd, "height width dim -> (height width) dim")
        cls_1d = self.cls_token[None, :] + 0 * self.mask_token
        storage_tokens_md = self.storage_tokens

        x_nd = jnp.concatenate([cls_1d, storage_tokens_md, x_nd], axis=0)

        rope_sincos = self.rope_embed(h=h, w=w)
        rope_2nd = jnp.stack(rope_sincos, axis=0)
        for block in self.blocks:
            x_nd = block(x_nd, rope_2nd)

        if self.cfg.untie_global_and_local_cls_norm:
            x_cls_reg_nd = x_nd[: self.cfg.n_storage_tokens + 1]
            x_norm_cls_reg = jax.vmap(self.norm)(x_cls_reg_nd)
        else:
            x_norm_nd = jax.vmap(self.norm)(x_nd)
            x_norm_cls_reg = x_norm_nd[: self.cfg.n_storage_tokens + 1]

        return x_norm_cls_reg[0]


@beartype.beartype
def load(fpath: str) -> VisionTransformer:
    with open(fpath, "rb") as fd:
        cfg_dict = json.loads(fd.readline())
        cfg = Config(**cfg_dict)
        model = VisionTransformer(cfg, key=jax.random.key(seed=0))
        return eqx.tree_deserialise_leaves(fd, model)


@beartype.beartype
def dump(model: VisionTransformer, fpath: str):
    with open(fpath, "wb") as fd:
        cfg_str = json.dumps(dataclasses.asdict(model.cfg))
        fd.write((cfg_str + "\n").encode("utf-8"))
        eqx.tree_serialise_leaves(fd, model)


@beartype.beartype
def _parse_name_pt(dinov3_ckpt: pathlib.Path) -> str:
    name_ds, sha = dinov3_ckpt.stem.split("-")
    *name, pretrain, ds = name_ds.split("_")
    assert pretrain == "pretrain"
    return "_".join(name)


_PRETRAINED_CFGS = {
    "dinov3_vits16": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=384,
        depth=12,
        num_heads=6,
        ffn_ratio=4.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="mlp",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
    ),
    "dinov3_vits16plus": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=384,
        depth=12,
        num_heads=6,
        ffn_ratio=6.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="swiglu",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
    ),
    "dinov3_vitb16": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=768,
        depth=12,
        num_heads=12,
        ffn_ratio=4.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="mlp",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
    ),
    "dinov3_vitl16": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=1024,
        depth=24,
        num_heads=16,
        ffn_ratio=4.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="mlp",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
        untie_global_and_local_cls_norm=False,
    ),
    "dinov3_vitl16plus": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=1024,
        depth=24,
        num_heads=16,
        ffn_ratio=6.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="swiglu",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
    ),
    "dinov3_vith16plus": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=1280,
        depth=32,
        num_heads=20,
        ffn_ratio=6.0,
        qkv_bias=True,
        drop_path_rate=0.0,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="swiglu",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
    ),
    "dinov3_vit7b16": Config(
        img_size=224,
        patch_size=16,
        in_chans=3,
        pos_embed_rope_base=100.0,
        pos_embed_rope_normalize_coords="separate",
        pos_embed_rope_rescale_coords=2.0,
        pos_embed_rope_dtype="fp32",
        embed_dim=4096,
        depth=40,
        num_heads=32,
        ffn_ratio=3.0,
        qkv_bias=False,
        drop_path_rate=0.4,
        layerscale_init=1.0e-05,
        norm_layer="layernormbf16",
        ffn_layer="swiglu64",
        ffn_bias=True,
        proj_bias=True,
        n_storage_tokens=4,
        mask_k_bias=True,
        untie_global_and_local_cls_norm=True,
    ),
}


def _tokenize(path: str) -> list[str | int]:
    """Split 'blocks.0.mlp.fc1.weight' -> ['blocks', 0, 'mlp', 'fc1', 'weight']"""
    toks = []
    for part in path.split("."):
        if part.isdigit():
            toks.append(int(part))
        else:
            toks.append(part)
    return toks


def _make_where(key: str) -> Callable[[PyTree], tp.Any]:
    toks = _tokenize(key)

    def _where(tree: PyTree) -> tp.Any:
        for attr in toks:
            if isinstance(attr, int):
                tree = tree[attr]
            else:
                try:
                    tree = getattr(tree, attr)
                except AttributeError as err:
                    raise ValueError(f"Missing attr '{key}': {err}") from err
        return tree

    return _where


def _to_jax(x) -> jnp.ndarray:
    # x: torch.Tensor or np.ndarray
    import torch  # import here to keep this file importable without torch installed

    if isinstance(x, torch.Tensor):
        arr = x.detach().cpu().numpy()
    elif isinstance(x, np.ndarray):
        arr = x
    else:
        raise TypeError(f"Unsupported tensor type: {type(x)}")
    out = jnp.asarray(arr)
    return out


@jaxtyped(typechecker=beartype.beartype)
def _coerce_to_jax(
    key: str, value, update_dst: Float[Array, "*axes"]
) -> Float[Array, "*axes"]:
    import difflib

    import torch  # import here to keep this file importable without torch installed

    if isinstance(value, torch.Tensor):
        value = value.detach().cpu().numpy()
    elif isinstance(value, np.ndarray):
        value = value
    else:
        raise TypeError(f"Unsupported tensor type: {type(value)}")
    value = jnp.asarray(value)

    if value.shape != update_dst.shape:
        for line in difflib.ndiff(value.shape, update_dst.shape):
            op, _, *rest = line
            if op == " ":
                # Same shape
                continue
            shape = int("".join(rest))
            if shape == 1:
                # Can reshape easily
                continue

            raise ValueError(
                f"Can't automatically reshape '{key}': {value.shape} => {update_dst.shape}"
            )

        print(f"Reshaping '{key}' from {value.shape} to {update_dst.shape}.")
        value = value.reshape(update_dst.shape)

    return value


def load_torch():
    pass


@beartype.beartype
def _convert(dinov3_ckpt: pathlib.Path, dump_to: pathlib.Path):
    """Convert DINOv3 checkpoints from PyTorch to Jax/Equinox.

    Run with `uv run --with torch src/btx/modeling/dinov3.py` to include torch.

    Args:
        dinov3_ckpt: The specific .pth checkpoint you want to convert.
        dump_to: Where to save the .eqx checkpoint file.
    """
    import tempfile

    import torch

    name = _parse_name_pt(dinov3_ckpt)
    if name not in _PRETRAINED_CFGS:
        raise ValueError(f"Name '{name}' not in {list(_PRETRAINED_CFGS)}.")

    vit_pt = torch.hub.load(
        "facebookresearch/dinov3", name, source="github", weights=str(dinov3_ckpt)
    )
    cfg = _PRETRAINED_CFGS[name]
    vit_eqx = VisionTransformer(cfg, key=jax.random.key(seed=0))

    for key, value in vit_pt.state_dict().items():
        where = _make_where(key)
        update_dst = where(vit_eqx)
        update_src = _coerce_to_jax(key, value, update_dst)
        vit_eqx = eqx.tree_at(where, vit_eqx, update_src)

    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir = pathlib.Path(tmpdir)
        dummy_fpath = str(tmpdir / "dummy.eqx")
        dump(vit_eqx, dummy_fpath)
        load(dummy_fpath)

    dump_to.mkdir(parents=True, exist_ok=True)
    fpath = str(dump_to / f"{name}.eqx")
    dump(vit_eqx, fpath)
    print(f"Saved to '{fpath}'.")


if __name__ == "__main__":
    import tyro

    tyro.cli(_convert)

>>>> modeling/toy.py
# src/btx/modeling/toy.py
import dataclasses

import beartype
import chex
import einops
import equinox as eqx
import jax
import jax.numpy as jnp
from jaxtyping import Array, Float, jaxtyped


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    img_size: int = 256
    patch: int = 16
    d_model: int = 192


@jaxtyped(typechecker=beartype.beartype)
class PatchEmbed(eqx.Module):
    proj: eqx.nn.Conv2d  # conv with stride = patch
    pos: Float[Array, "n_patches+1 d_model"]

    def __init__(
        self,
        patch: int = 16,
        d_model: int = 192,
        img_size: int = 256,
        *,
        key: chex.PRNGKey,
    ):
        k1, k2 = jax.random.split(key)
        self.proj = eqx.nn.Conv2d(
            in_channels=3,
            out_channels=d_model,
            kernel_size=patch,
            stride=patch,
            padding=0,
            key=k1,
        )
        n_patches = (img_size // patch) ** 2
        self.pos = jax.random.normal(k2, (n_patches + 1, d_model)) * 0.02

    def __call__(self, x_cwh: Float[Array, "c w h"]):
        x_dwh = self.proj(x_cwh)  # (B,E,H',W')
        x_pd = einops.rearrange(x_dwh, "d w h -> (w h) d")
        cls_1d = einops.reduce(x_pd, "patches d -> 1 d", "mean")
        x_pd = jnp.concatenate([cls_1d, x_pd], axis=0) + self.pos
        return x_pd


@jaxtyped(typechecker=beartype.beartype)
class Model(eqx.Module):
    patch: PatchEmbed
    head: eqx.nn.Linear

    def __init__(self, cfg: Config, *, key: chex.PRNGKey):
        k1, k2 = jax.random.split(key)
        self.patch = PatchEmbed(cfg.patch, cfg.d_model, cfg.img_size, key=k1)
        # Predict 8 coordinates: two measurements x (x, y) x 2 endpoints
        self.head = eqx.nn.Linear(cfg.d_model, 8, key=k2)

    def __call__(
        self, x_whc: Float[Array, "w h c"], *, key: chex.PRNGKey | None = None
    ) -> Float[Array, "2 2 2"]:
        x_cwh = einops.rearrange(x_whc, "w h c -> c w h")
        x_pd = self.patch(x_cwh)
        cls_d = x_pd[0, :]
        coords = self.head(cls_d)
        return coords.reshape(2, 2, 2)

>>>> scripts/download_beetlepalooza.py
# src/btx/scripts/download_beetlepalooza.py
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "huggingface_hub",
#     "requests",
#     "tyro",
# ]
# ///
import pathlib

import huggingface_hub as hfhub
import tyro


def main(dump_to: pathlib.Path = pathlib.Path("data/beetlepalooza")):
    hfhub.snapshot_download(
        repo_id="imageomics/2018-NEON-beetles",
        repo_type="dataset",
        local_dir=str(dump_to),
        allow_patterns=[
            "individual_specimens/**/*.png",
            "*.csv",
            "README.md",
        ],
        revision="refs/pr/25",
        max_workers=8,
    )


if __name__ == "__main__":
    tyro.cli(main)

>>>> scripts/download_biorepo.py
# src/btx/scripts/download_biorepo.py
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "huggingface_hub",
#     "requests",
#     "tyro",
# ]
# ///
import pathlib

import huggingface_hub as hfhub
import tyro


def main(dump_to: pathlib.Path = pathlib.Path("data/biorepo")):
    hfhub.snapshot_download(
        repo_id="imageomics/sentinel-beetles",
        repo_type="dataset",
        local_dir=str(dump_to),
        allow_patterns=[
            "data/*.parquet",
            "*.csv",
            "README.md",
        ],
        max_workers=8,
    )


if __name__ == "__main__":
    tyro.cli(main)

>>>> scripts/download_hawaii.py
# src/btx/scripts/download_hawaii.py
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "huggingface_hub",
#     "requests",
#     "tyro",
# ]
# ///
import pathlib

import huggingface_hub as hfhub
import tyro


def main(dump_to: pathlib.Path = pathlib.Path("data/hawaii")):
    hfhub.snapshot_download(
        repo_id="imageomics/Hawaii-beetles",
        repo_type="dataset",
        local_dir=str(dump_to),
        # allow_patterns=["individual_specimens/*.png", "*.csv", "README.md"],
        allow_patterns=["*.png", "*.csv", "README.md"],
        max_workers=8,
    )


if __name__ == "__main__":
    tyro.cli(main)

>>>> scripts/format_beetlepalooza.py
import dataclasses
import pathlib

import beartype
import tyro


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    hf_root: pathlib.Path = pathlib.Path("./data/beetlepalooza")
    """Where you dumped data when using download_beetlepalooza.py."""


@beartype.beartype
def main(cfg: Config):
    pass


if __name__ == "__main__":
    try:
        raise SystemExit(main(tyro.cli(Config)))
    except KeyboardInterrupt:
        print("Interrupted.")
        raise SystemExit(130)

>>>> scripts/format_hawaii.py
# src/btx/scripts/format_hawaii.py
"""
Some context:

[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles [1]> pwd
/fs/scratch/PAS2136/samuelstevens/datasets/hawaii-beetles
[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles> ls
group_images  images_metadata.csv  individual_specimens  README.md  trait_annotations.csv
[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles> ls group_images/ | head
IMG_0093.png
IMG_0095.png
IMG_0109.png
IMG_0110.png
IMG_0111.png
IMG_0112.png
IMG_0113.png
IMG_0114.png
IMG_0115.png
IMG_0116.png
[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles> ls individual_specimens/ | head
IMG_0093_specimen_1_MECKON_NEON.BET.D20.000001.png
IMG_0093_specimen_2_MECKON_NEON.BET.D20.000003.png
IMG_0093_specimen_3_MECKON_NEON.BET.D20.000004.png
IMG_0095_specimen_1_MECKON_NEON.BET.D20.000005.png
IMG_0095_specimen_2_MECKON_NEON.BET.D20.000007.png
IMG_0095_specimen_3_MECKON_NEON.BET.D20.000010.png
IMG_0109_specimen_1_MECKON_NEON.BET.D20.000011.png
IMG_0109_specimen_2_MECKON_NEON.BET.D20.000017.png
IMG_0109_specimen_3_MECKON_NEON.BET.D20.000026.png
IMG_0110_specimen_1_MECKON_NEON.BET.D20.000035.png
[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles> head trait_annotations.csv
groupImageFilePath,BeetlePosition,individualID,coords_scalebar,coords_elytra_max_length,coords_basal_pronotum_width,coords_elytra_max_width,px_scalebar,px_elytra_max_length,px_basal_pronotum_width,px_elytra_max_width,cm_scalebar,cm_elytra_max_length,cm_basal_pronotum_width,cm_elytra_max_width
group_images/IMG_0093.png,1,NEON.BET.D20.000001,"[[5713.91, 3045.68, 5701.21, 2265.92]]","[[3865.5, 1245.87, 3881.25, 1045.81]]","[[3922.92, 1046.2, 3872.53, 1035.06]]","[[3960.08, 1145.79, 3814.38, 1123.85]]",779.8634159902615,200.67901260470657,51.606702084128464,147.34264012837542,1.0,0.257,0.066,0.189
group_images/IMG_0093.png,2,NEON.BET.D20.000003,"[[5713.91, 3045.68, 5701.21, 2265.92]]","[[3899.77, 2528.67, 3939.62, 2338.98]]","[[3961.39, 2339.49, 3912.19, 2329.79]]","[[3974.62, 2440.72, 3895.98, 2421]]",779.8634159902615,193.8306441200669,50.14708366395775,81.07482963287664,1.0,0.249,0.064,0.104
group_images/IMG_0093.png,3,NEON.BET.D20.000004,"[[5713.91, 3045.68, 5701.21, 2265.92]]","[[3998.51, 3859.69, 4002.25, 3686.53]]","[[4047.58, 3684.09, 4013.58, 3681.39]]","[[4080.85, 3774.4, 3959.48, 3763.86]]",779.8634159902615,173.2003845261319,34.1070373969948,121.82679713429216,1.0,0.222,0.044,0.156
group_images/IMG_0095.png,1,NEON.BET.D20.000005,"[[4361.9, 3001.51, 4356.57, 2218.33]]","[[2727.56, 991.13, 2777.05, 746.39]]","[[2771.23, 737.52, 2719.33, 714.82]]","[[2819.12, 840.3, 2651.68, 832.24]]",783.1981366806234,249.69366772106983,56.64715350306674,167.63387843750445,1.0,0.319,0.072,0.214
group_images/IMG_0095.png,2,NEON.BET.D20.000007,"[[4361.9, 3001.51, 4356.57, 2218.33]]","[[2637.35, 2011.99, 2701.51, 1851.59]]","[[2703.39, 1846.64, 2660.39, 1834.34]]","[[2721.27, 1936.92, 2601.72, 1899.58]]",783.1981366806234,172.7560870128751,44.72460173103842,125.24567098307251,1.0,0.221,0.057,0.16
group_images/IMG_0095.png,3,NEON.BET.D20.000010,"[[4361.9, 3001.51, 4356.57, 2218.33]]","[[2665.12, 2947.47, 2726.98, 2725.72]]","[[2725.91, 2711.99, 2675.41, 2705.29]]","[[2755.34, 2836.81, 2597.89, 2812.56]]",783.1981366806234,230.2166851034043,50.94251662413232,159.30651273566968,1.0,0.294,0.065,0.203
group_images/IMG_0109.png,1,NEON.BET.D20.000011,"[[5963.41, 2293.36, 5928.69, 1510.68]]","[[4369.81, 1151.98, 4434.72, 964.11]]","[[4435.89, 958.48, 4390.69, 941.68]]","[[4453.82, 1063.75, 4319.9, 1024.04]]",783.4497181057634,198.767313711284,48.22115718229985,139.68339378752228,1.0,0.254,0.062,0.178
group_images/IMG_0109.png,2,NEON.BET.D20.000017,"[[5963.41, 2293.36, 5928.69, 1510.68]]","[[4332.92, 1979.73, 4335.18, 1781.63]]","[[4395.78, 1775.08, 4340.7, 1755.66]]","[[4428.95, 1868.03, 4287.33, 1862.43]]",783.4497181057634,198.1128910495225,58.40327730530185,141.73067557871858,1.0,0.253,0.075,0.181
group_images/IMG_0109.png,3,NEON.BET.D20.000026,"[[5963.41, 2293.36, 5928.69, 1510.68]]","[[4264.26, 2738.34, 4313.08, 2537.98]]","[[4362.27, 2538.03, 4321.57, 2526.78]]","[[4386.88, 2641.59, 4329.2, 2638.75, 4324.27, 2637.61, 4245.53, 2614.46]]",783.4497181057634,206.2220211325649,42.2262063178787,139.82246488940592,1.0,0.263,0.054,0.178
[I] samuelstevens@ascend-login01 /f/s/P/s/d/hawaii-beetles> head images_metadata.csv
individualImageFilePath,groupImageFilePath,individualID,taxonID,scientificName,plotID,trapID,plotTrapID,collectDate,ownerInstitutionCode,catalogNumber
individual_specimens/IMG_0093_specimen_1_MECKON_NEON.BET.D20.000001.png,group_images/IMG_0093.png,NEON.BET.D20.000001,MECKON,Mecyclothorax konanus,6,W,006W,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0093_specimen_2_MECKON_NEON.BET.D20.000003.png,group_images/IMG_0093.png,NEON.BET.D20.000003,MECKON,Mecyclothorax konanus,16,W,016W,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0093_specimen_3_MECKON_NEON.BET.D20.000004.png,group_images/IMG_0093.png,NEON.BET.D20.000004,MECKON,Mecyclothorax konanus,6,E,006E,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0095_specimen_1_MECKON_NEON.BET.D20.000005.png,group_images/IMG_0095.png,NEON.BET.D20.000005,MECKON,Mecyclothorax konanus,14,S,014S,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0095_specimen_2_MECKON_NEON.BET.D20.000007.png,group_images/IMG_0095.png,NEON.BET.D20.000007,MECKON,Mecyclothorax konanus,6,E,006E,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0095_specimen_3_MECKON_NEON.BET.D20.000010.png,group_images/IMG_0095.png,NEON.BET.D20.000010,MECKON,Mecyclothorax konanus,14,W,014W,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0109_specimen_1_MECKON_NEON.BET.D20.000011.png,group_images/IMG_0109.png,NEON.BET.D20.000011,MECKON,Mecyclothorax konanus,14,E,014E,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0109_specimen_2_MECKON_NEON.BET.D20.000017.png,group_images/IMG_0109.png,NEON.BET.D20.000017,MECKON,Mecyclothorax konanus,14,S,014S,20190424,NEON,DP1.10022.001
individual_specimens/IMG_0109_specimen_3_MECKON_NEON.BET.D20.000026.png,group_images/IMG_0109.png,NEON.BET.D20.000026,MECKON,Mecyclothorax konanus,14,W,014W,20190424,NEON,DP1.10022.001
"""

import dataclasses
import gc
import itertools
import json
import logging
import pathlib
import resource
import time

import beartype
import numpy as np
import polars as pl
import skimage.feature
import submitit
import tyro
from jaxtyping import Float, UInt
from PIL import Image, ImageDraw

import btx.helpers

log_format = "[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s"


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    hf_root: pathlib.Path = pathlib.Path("./data/hawaii")
    """Where you dumped data when using download_hawaii.py."""

    log_to: pathlib.Path = pathlib.Path("./logs")
    """Where to save submitit/slurm logs."""

    dump_to: pathlib.Path = pathlib.Path("./data/hawaii-formatted")
    """Where to save formatted data."""

    ignore_errors: bool = False
    """Skip the user error check and always proceed (equivalent to answering 'yes')."""

    seed: int = 42
    """Random seed for sampling which annotations to save as examples."""

    sample_rate: int = 20
    """Save 1 in sample_rate annotations as example images (default: 1 in 20)."""

    # Slurm configuration
    slurm_acct: str = ""
    """Slurm account to use. If empty, uses DebugExecutor."""

    slurm_partition: str = "parallel"
    """Slurm partition to use."""

    n_hours: float = 2.0
    """Number of hours to request for each job."""

    groups_per_job: int = 4
    """Number of group images to process per job."""


@beartype.beartype
def img_as_arr(
    img: Image.Image | pathlib.Path,
) -> Float[np.ndarray, "height width channels"]:
    img = img if isinstance(img, Image.Image) else Image.open(img)
    return np.asarray(img, dtype=np.float32)


@beartype.beartype
def img_as_grayscale(
    img: Image.Image | pathlib.Path,
) -> UInt[np.ndarray, "height width"]:
    img = img if isinstance(img, Image.Image) else Image.open(img)
    # Convert to grayscale using PIL (more efficient than loading RGB then converting)
    return np.asarray(img.convert("L"))


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class WorkerError(Exception):
    """Base class for worker errors with context."""

    group_img_basename: str
    message: str

    def __str__(self):
        return f"{self.group_img_basename}: {self.message}"


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class TemplateMatchingError(WorkerError):
    """Error during template matching."""

    beetle_position: int
    indiv_img_path: str

    def __str__(self):
        return f"{self.group_img_basename} (beetle {self.beetle_position}): Template matching failed for {self.indiv_img_path} - {self.message}"


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class ImageLoadError(WorkerError):
    """Error loading an image file."""

    img_path: str

    def __str__(self):
        return f"{self.group_img_basename}: Failed to load {self.img_path} - {self.message}"


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Annotation:
    group_img_basename: str
    beetle_position: int
    group_img_abs_path: pathlib.Path
    indiv_img_abs_path: pathlib.Path
    indiv_offset_px: tuple[float, float]
    individual_id: str
    ncc: float
    """Normalized cross-correlation score from template matching."""
    taxon_id: str
    """Six letter taxon ID code."""
    scientific_name: str
    """Scientific name (genus species)."""

    def to_dict(self) -> dict:
        """Convert annotation to dictionary for JSON serialization."""
        return {
            "group_img_basename": self.group_img_basename,
            "beetle_position": self.beetle_position,
            "group_img_rel_path": f"group_images/{self.group_img_basename.upper()}.png",
            "indiv_img_rel_path": str(self.indiv_img_abs_path).split("/hawaii/")[-1]
            if "/hawaii/" in str(self.indiv_img_abs_path)
            else str(self.indiv_img_abs_path.name),
            "indiv_img_abs_path": str(self.indiv_img_abs_path),
            "individual_id": self.individual_id,
            "origin_x": int(self.indiv_offset_px[0]),
            "origin_y": int(self.indiv_offset_px[1]),
            "ncc": self.ncc,
            "taxon_id": self.taxon_id,
            "scientific_name": self.scientific_name,
        }


@beartype.beartype
def save_example_images(
    dump_to: pathlib.Path, annotation: Annotation, trait_data: dict[str, object]
) -> None:
    """Save example images with annotations drawn on them."""
    # Define colors for different trait types (RGB)
    trait_colors = {
        "coords_elytra_max_length": (0, 255, 0),  # Green
        "coords_basal_pronotum_width": (0, 0, 255),  # Blue
        "coords_elytra_max_width": (255, 255, 0),  # Yellow
    }
    logging.basicConfig(level=logging.INFO, format=log_format)
    logger = logging.getLogger("save-imgs")

    # Load images for drawing
    try:
        group_img_pil = Image.open(annotation.group_img_abs_path).convert("RGB")
        indiv_img_pil = Image.open(annotation.indiv_img_abs_path).convert("RGB")
    except Exception as e:
        logger.warning(
            "Failed to load images for example: %s beetle %d - %s",
            annotation.group_img_basename,
            annotation.beetle_position,
            e,
        )
        return

    # Get individual image dimensions
    indiv_w, indiv_h = indiv_img_pil.size
    x, y = annotation.indiv_offset_px

    # Draw on group image
    group_draw = ImageDraw.Draw(group_img_pil)

    # Draw bounding box around individual beetle
    group_draw.rectangle(
        (x, y, x + indiv_w, y + indiv_h),
        outline=(255, 0, 0),
        width=12,
    )

    # Draw polylines for each trait type on group image
    for trait_name, color in trait_colors.items():
        if trait_name not in trait_data:
            continue

        coords = trait_data[trait_name]
        if not coords:
            continue

        for polyline in coords:
            if len(polyline) < 2:
                continue

            # Check that polyline has even number of coordinates (x,y pairs)
            if len(polyline) % 2 != 0:
                logger.warning(
                    "Polyline for %s has odd number of coordinates (%d) for %s beetle %d. Skipping.",
                    trait_name,
                    len(polyline),
                    annotation.group_img_basename,
                    annotation.beetle_position,
                )
                continue

            # Convert to list of tuples for PIL
            points = list(itertools.batched(polyline, 2))
            if len(points) < 2:
                continue

            group_draw.line(points, fill=color, width=8)

    # Draw on individual image with adjusted coordinates
    indiv_draw = ImageDraw.Draw(indiv_img_pil)

    for trait_name, color in trait_colors.items():
        if trait_name not in trait_data:
            continue

        coords = trait_data[trait_name]
        if not coords:
            continue

        for polyline in coords:
            if len(polyline) < 2:
                continue

            # Check that polyline has even number of coordinates (x,y pairs)
            if len(polyline) % 2 != 0:
                logger.warning(
                    "Polyline for %s has odd number of coordinates (%d) for %s beetle %d. Skipping.",
                    trait_name,
                    len(polyline),
                    annotation.group_img_basename,
                    annotation.beetle_position,
                )
                continue

            # Adjust coordinates relative to individual image
            adjusted_points = [
                (pt[0] - x, pt[1] - y) for pt in itertools.batched(polyline, 2)
            ]

            # Filter and warn about out-of-bounds points
            valid_points = []
            invalid_count = 0
            for px, py in adjusted_points:
                if 0 <= px < indiv_w and 0 <= py < indiv_h:
                    valid_points.append((px, py))
                else:
                    invalid_count += 1

            if invalid_count > 0:
                logger.warning(
                    "Found %d out-of-bounds points for %s on %s beetle %d (discarded from drawing)",
                    invalid_count,
                    trait_name,
                    annotation.group_img_basename,
                    annotation.beetle_position,
                )

            if len(valid_points) < 2:
                continue

            indiv_draw.line(valid_points, fill=color, width=3)

    # Resize group image for viewing
    group_w, group_h = group_img_pil.size
    resized_group = group_img_pil.resize((group_w // 10, group_h // 10))

    # Save images
    examples_dir = dump_to / "random-examples"
    group_path = (
        examples_dir
        / f"{annotation.group_img_basename}_beetle{annotation.beetle_position}_group.png"
    )
    indiv_path = (
        examples_dir
        / f"{annotation.group_img_basename}_beetle{annotation.beetle_position}_individual.png"
    )

    resized_group.save(group_path)
    indiv_img_pil.save(indiv_path)

    logger.info(
        "Saved example images for %s beetle %d",
        annotation.group_img_basename,
        annotation.beetle_position,
    )


@beartype.beartype
def get_memory_info() -> dict[str, float]:
    """Get current memory usage information."""
    try:
        with open("/proc/meminfo", "r") as f:
            lines = f.readlines()
        meminfo = {}
        for line in lines:
            parts = line.split()
            if len(parts) >= 2:
                key = parts[0].rstrip(":")
                value = int(parts[1])
                meminfo[key] = value

        mem_total_gb = meminfo.get("MemTotal", 0) / (1024 * 1024)
        mem_available_gb = meminfo.get("MemAvailable", 0) / (1024 * 1024)
        mem_free_gb = meminfo.get("MemFree", 0) / (1024 * 1024)

        # Also get process-specific memory
        usage = resource.getrusage(resource.RUSAGE_SELF)
        process_mem_gb = usage.ru_maxrss / (1024 * 1024)  # Linux reports in KB

        return {
            "total_gb": round(mem_total_gb, 2),
            "available_gb": round(mem_available_gb, 2),
            "free_gb": round(mem_free_gb, 2),
            "used_gb": round(mem_total_gb - mem_available_gb, 2),
            "process_gb": round(process_mem_gb, 2),
            "percent_used": round(
                (mem_total_gb - mem_available_gb) / mem_total_gb * 100, 1
            ),
        }
    except Exception as e:
        return {"error": str(e)}


@beartype.beartype
def worker_fn(
    cfg: Config, group_img_basenames: list[str]
) -> list[Annotation | WorkerError]:
    """Worker. Processing group_img_basenames and returns a list of annotations or errors."""
    logging.basicConfig(level=logging.DEBUG, format=log_format)
    logger = logging.getLogger("worker")

    # Log initial memory state
    mem_info = get_memory_info()
    logger.info(
        "Starting worker with %d group images. Memory: %s",
        len(group_img_basenames),
        mem_info,
    )

    # Load dataframes
    img_df = load_img_df(cfg)
    logger.info(
        "Loaded img_df with %d rows. Memory: %s", len(img_df), get_memory_info()
    )

    trait_df = load_trait_df(cfg)
    logger.info(
        "Loaded trait_df with %d rows. Memory: %s", len(trait_df), get_memory_info()
    )

    # Filter to only relevant data to save memory
    logger.info("Filtering dataframes to relevant groups...")
    img_df = img_df.filter(pl.col("GroupImgBasename").is_in(group_img_basenames))
    trait_df = trait_df.filter(pl.col("GroupImgBasename").is_in(group_img_basenames))
    logger.info(
        "After filtering - img_df: %d rows, trait_df: %d rows. Memory: %s",
        len(img_df),
        len(trait_df),
        get_memory_info(),
    )

    results = []

    # Initialize random number generator for sampling
    rng = np.random.default_rng(seed=cfg.seed)

    for idx, group_img_basename in enumerate(group_img_basenames):
        logger.info(
            "Processing group %d/%d: %s. Memory before: %s",
            idx + 1,
            len(group_img_basenames),
            group_img_basename,
            get_memory_info(),
        )

        # Construct the group image path (need to uppercase the basename for filesystem)
        group_img_abs_path = (
            cfg.hf_root / "group_images" / f"{group_img_basename.upper()}.png"
        )

        # Load the group image in grayscale for matching.
        try:
            group_img_gray = img_as_grayscale(group_img_abs_path)
            logger.info(
                "Loaded group image %s, gray shape: %s. Memory: %s",
                group_img_basename,
                group_img_gray.shape,
                get_memory_info(),
            )
        except Exception as e:
            logger.error("Failed to load group image %s: %s", group_img_basename, e)
            results.append(
                ImageLoadError(
                    group_img_basename=group_img_basename,
                    message=str(e),
                    img_path=str(group_img_abs_path),
                )
            )
            continue

        # Find all individual images for this group image
        group_rows = img_df.filter(pl.col("GroupImgBasename") == group_img_basename)
        logger.info(
            "Found %d individual images for group %s",
            len(group_rows),
            group_img_basename,
        )

        for row in group_rows.iter_rows(named=True):
            beetle_position = row["BeetlePosition"]
            indiv_img_rel_path = row["individualImageFilePath"]
            indiv_img_abs_path = cfg.hf_root / indiv_img_rel_path

            # Load the individual image (grayscale for matching)
            try:
                template_gray = img_as_grayscale(indiv_img_abs_path)
                logger.debug(
                    "Loaded individual image for beetle %d, gray shape: %s. Memory: %s",
                    beetle_position,
                    template_gray.shape,
                    get_memory_info(),
                )
            except Exception as e:
                logger.error(
                    "Failed to load individual image for beetle %d: %s",
                    beetle_position,
                    e,
                )
                results.append(
                    ImageLoadError(
                        group_img_basename=group_img_basename,
                        message=str(e),
                        img_path=str(indiv_img_abs_path),
                    )
                )
                continue

            # Perform template matching (using grayscale images)
            try:
                logger.debug(
                    "Starting template matching for beetle %d...", beetle_position
                )
                corr = skimage.feature.match_template(
                    group_img_gray, template_gray, pad_input=False
                )
                logger.debug(
                    "Template matching complete, corr shape: %s. Memory: %s",
                    corr.shape,
                    get_memory_info(),
                )

                if corr.size == 0:
                    raise ValueError(
                        "Empty correlation map - template may be larger than image"
                    )

                max_corr_idx = np.argmax(corr)
                iy, ix = np.unravel_index(max_corr_idx, corr.shape)
                offset_px = float(ix), float(iy)

                # Get the normalized cross-correlation score at the best match
                ncc_score = float(corr.flat[max_corr_idx])

                # Clean up correlation matrix to free memory
                del corr
                del template_gray
                gc.collect()

                # Get individual ID from the row data
                individual_id = row.get("individualID", "")
                taxon_id = row.get("taxonID", "")
                scientific_name = row.get("scientificName", "")

                annotation = Annotation(
                    group_img_basename=group_img_basename,
                    beetle_position=beetle_position,
                    group_img_abs_path=group_img_abs_path,
                    indiv_img_abs_path=indiv_img_abs_path,
                    indiv_offset_px=offset_px,
                    individual_id=individual_id,
                    ncc=ncc_score,
                    taxon_id=taxon_id,
                    scientific_name=scientific_name,
                )

                # Save a random subset of annotations as example images
                if rng.integers(0, cfg.sample_rate) == 0:
                    trait_row = trait_df.filter(
                        (pl.col("GroupImgBasename") == annotation.group_img_basename)
                        & (pl.col("BeetlePosition") == annotation.beetle_position)
                    )

                    if not trait_row.is_empty():
                        trait_data = trait_row.to_dicts()[0]
                        save_example_images(cfg.dump_to, annotation, trait_data)
                        logger.debug(
                            "Saved example image. Memory: %s", get_memory_info()
                        )
                    else:
                        # TODO: log that there are no traits for this group image and beetle position.
                        pass

                results.append(annotation)

            except Exception as e:
                results.append(
                    TemplateMatchingError(
                        group_img_basename=group_img_basename,
                        message=str(e),
                        beetle_position=beetle_position,
                        indiv_img_path=str(indiv_img_abs_path),
                    )
                )

        # Clean up group images after processing all individuals
        del group_img_gray
        gc.collect()
        logger.info(
            "Finished processing group %s. Memory after cleanup: %s",
            group_img_basename,
            get_memory_info(),
        )

    logger.info(
        "Worker completed. Processed %d groups, %d results. Final memory: %s",
        len(group_img_basenames),
        len(results),
        get_memory_info(),
    )
    return results


@beartype.beartype
def load_trait_df(cfg: Config) -> pl.DataFrame:
    return pl.read_csv(cfg.hf_root / "trait_annotations.csv").with_columns(
        pl.col("groupImageFilePath")
        .str.to_lowercase()
        .str.strip_prefix("group_images/")
        .str.strip_suffix(".png")
        .alias("GroupImgBasename"),
        pl.col("coords_scalebar").str.json_decode(),
        pl.col("coords_elytra_max_length").str.json_decode(),
        pl.col("coords_basal_pronotum_width").str.json_decode(),
        pl.col("coords_elytra_max_width").str.json_decode(),
    )


@beartype.beartype
def load_img_df(cfg: Config) -> pl.DataFrame:
    return pl.read_csv(cfg.hf_root / "images_metadata.csv").with_columns(
        pl.col("groupImageFilePath")
        .str.to_lowercase()
        .str.strip_prefix("group_images/")
        .str.strip_suffix(".png")
        .alias("GroupImgBasename"),
        pl.col("individualImageFilePath")
        .str.to_lowercase()
        .str.extract(r"specimen_(\d+)", 1)
        .cast(pl.Int64)
        .alias("BeetlePosition"),
    )


@beartype.beartype
def main(cfg: Config) -> int:
    logging.basicConfig(level=logging.INFO, format=log_format)
    logger = logging.getLogger("format-hawaii")
    errors = []

    trait_df = load_trait_df(cfg)
    # Check that there are no duplicate unique keys
    trait_dups = (
        trait_df.group_by("GroupImgBasename", "BeetlePosition")
        .len()
        .filter(pl.col("len") > 1)
    )
    if not trait_dups.is_empty():
        error_msg = f"Found {len(trait_dups)} duplicate GroupImgBasename/BeetlePosition combinations in trait annotations"
        logger.error(error_msg)
        errors.append(("trait_duplicates", len(trait_dups)))
        for row in trait_dups.iter_rows(named=True):
            logger.error(
                "  GroupImgBasename: %s, BeetlePosition: %s, count: %d",
                row["GroupImgBasename"],
                row["BeetlePosition"],
                row["len"],
            )

    img_df = load_img_df(cfg)
    img_dups = (
        img_df.group_by("GroupImgBasename", "BeetlePosition")
        .len()
        .filter(pl.col("len") > 1)
    )
    if not img_dups.is_empty():
        error_msg = f"Found {len(img_dups)} duplicate GroupImgBasename/BeetlePosition combinations in images metadata"
        logger.error(error_msg)
        errors.append(("image_duplicates", len(img_dups)))
        for row in img_dups.iter_rows(named=True):
            logger.error(
                "  GroupImgBasename: %s, BeetlePosition: %s, count: %d",
                row["GroupImgBasename"],
                row["BeetlePosition"],
                row["len"],
            )

    # Check for rows in img_df that are not in trait_df
    img_keys = img_df.select("GroupImgBasename", "BeetlePosition").unique()
    trait_keys = trait_df.select("GroupImgBasename", "BeetlePosition").unique()

    img_not_in_trait = img_keys.join(
        trait_keys, on=["GroupImgBasename", "BeetlePosition"], how="anti"
    )
    if not img_not_in_trait.is_empty():
        error_msg = f"Found {len(img_not_in_trait)} image entries without corresponding trait annotations"
        logger.error(error_msg)
        errors.append(("images_without_traits", len(img_not_in_trait)))
        for row in img_not_in_trait.head(10).iter_rows(named=True):
            logger.error(
                "  GroupImgBasename: %s, BeetlePosition: %s",
                row["GroupImgBasename"],
                row["BeetlePosition"],
            )
        if len(img_not_in_trait) > 10:
            logger.error("  ... and %d more", len(img_not_in_trait) - 10)

    # Check for rows in trait_df that are not in img_df
    trait_not_in_img = trait_keys.join(
        img_keys, on=["GroupImgBasename", "BeetlePosition"], how="anti"
    )
    if not trait_not_in_img.is_empty():
        error_msg = f"Found {len(trait_not_in_img)} trait annotations without corresponding image entries"
        logger.error(error_msg)
        errors.append(("traits_without_images", len(trait_not_in_img)))
        for row in trait_not_in_img.head(10).iter_rows(named=True):
            logger.error(
                "  GroupImgBasename: %s, BeetlePosition: %s",
                row["GroupImgBasename"],
                row["BeetlePosition"],
            )
        if len(trait_not_in_img) > 10:
            logger.error("  ... and %d more", len(trait_not_in_img) - 10)

    # Check that image files exist
    logger.info("Checking that image files exist.")

    # Get all unique file paths
    all_group_paths = set(img_df["groupImageFilePath"].unique().to_list())
    all_individual_paths = set(img_df["individualImageFilePath"].unique().to_list())
    all_paths = all_group_paths | all_individual_paths

    missing_files = []
    corrupted_files = []

    for i, rel_path in enumerate(
        btx.helpers.progress(
            sorted(all_paths), every=len(all_paths) // 10, desc="file existence"
        )
    ):
        full_path = cfg.hf_root / rel_path
        if not full_path.exists():
            missing_files.append(rel_path)
        else:
            # Try to open the file to check if it's corrupted
            try:
                with Image.open(full_path) as img:
                    _ = img.size  # Force loading to check corruption
            except Exception as e:
                corrupted_files.append((rel_path, str(e)))

    if missing_files:
        error_msg = f"Found {len(missing_files)} missing image files"
        logger.error(error_msg)
        errors.append(("missing_files", len(missing_files)))
        for path in missing_files[:10]:
            logger.error("  Missing: %s", path)
        if len(missing_files) > 10:
            logger.error("  ... and %d more", len(missing_files) - 10)

    if corrupted_files:
        error_msg = f"Found {len(corrupted_files)} corrupted image files"
        logger.error(error_msg)
        errors.append(("corrupted_files", len(corrupted_files)))
        for path, error in corrupted_files[:10]:
            logger.error("  Corrupted: %s (%s)", path, error)
        if len(corrupted_files) > 10:
            logger.error("  ... and %d more", len(corrupted_files) - 10)

    logger.info("Checking image dimensions.")

    # Get unique group images with their corresponding individual images
    group_to_individuals = (
        img_df.group_by("groupImageFilePath")
        .agg(pl.col("individualImageFilePath").unique())
        .to_dicts()
    )

    dimension_errors = []
    for group_data in btx.helpers.progress(
        group_to_individuals,
        every=len(group_to_individuals) // 10,
        desc="dimension check",
    ):
        group_path = cfg.hf_root / group_data["groupImageFilePath"]

        # Skip if file doesn't exist (already reported)
        if not group_path.exists():
            continue

        try:
            with Image.open(group_path) as group_img:
                group_width, group_height = group_img.size

                for individual_rel_path in group_data["individualImageFilePath"]:
                    individual_path = cfg.hf_root / individual_rel_path

                    # Skip if file doesn't exist (already reported)
                    if not individual_path.exists():
                        continue

                    try:
                        with Image.open(individual_path) as ind_img:
                            ind_width, ind_height = ind_img.size

                            if ind_width >= group_width or ind_height >= group_height:
                                dimension_errors.append({
                                    "group": group_data["groupImageFilePath"],
                                    "individual": individual_rel_path,
                                    "group_size": (group_width, group_height),
                                    "individual_size": (ind_width, ind_height),
                                })
                    except Exception:
                        # Skip corrupted files (already reported)
                        pass

        except Exception:
            # Skip corrupted files (already reported)
            pass

    if dimension_errors:
        error_msg = (
            f"Found {len(dimension_errors)} dimension validation errors in sample"
        )
        logger.error(error_msg)
        errors.append(("dimension_errors", len(dimension_errors)))
        for err in dimension_errors[:5]:
            logger.error(
                "  Individual %s (%dx%d) >= Group %s (%dx%d)",
                err["individual"],
                err["individual_size"][0],
                err["individual_size"][1],
                err["group"],
                err["group_size"][0],
                err["group_size"][1],
            )
        if len(dimension_errors) > 5:
            logger.error("  ... and %d more", len(dimension_errors) - 5)

    # If there are errors, summarize and ask user if they want to proceed
    if errors:
        print("\n" + "=" * 60)
        print("DATA VALIDATION SUMMARY")
        print("=" * 60)
        print("\nThe following issues were found:")
        for error_type, count in errors:
            print(f"  - {error_type.replace('_', ' ').title()}: {count}")

        print("\n" + "=" * 60)

        if cfg.ignore_errors:
            logger.warning("Ignoring errors due to --ignore-errors flag. Continuing.")
        else:
            response = input(
                "\nDo you want to continue with template matching despite these errors? (yes/no): "
            )
            if response.lower() not in ["yes", "y"]:
                logger.info("Exiting.")
                return 1
            logger.info("Continuing.")
    else:
        logger.info("No data validation errors found.")

    logger.info("Ready for parallel processing implementation.")

    # Create output directory for example images
    examples_dir = cfg.dump_to / "random-examples"
    examples_dir.mkdir(parents=True, exist_ok=True)
    logger.info("Example images will be saved to %s", examples_dir)

    # Get all unique group images to process
    all_group_basenames = trait_df.get_column("GroupImgBasename").unique().to_list()
    logger.info("Found %d unique group images to process", len(all_group_basenames))

    # Batch group images into chunks for each job
    group_batches = list(
        btx.helpers.batched_idx(len(all_group_basenames), cfg.groups_per_job)
    )
    logger.info(
        "Will process %d group images in %d jobs (%d groups per job)",
        len(all_group_basenames),
        len(group_batches),
        cfg.groups_per_job,
    )

    # Set up executor based on whether we're using Slurm
    if cfg.slurm_acct:
        # Calculate safe limits for Slurm
        max_array_size = btx.helpers.get_slurm_max_array_size()
        max_submit_jobs = btx.helpers.get_slurm_max_submit_jobs()

        safe_array_size = min(int(max_array_size * 0.95), max_array_size - 2)
        safe_array_size = max(1, safe_array_size)

        safe_submit_jobs = min(int(max_submit_jobs * 0.95), max_submit_jobs - 2)
        safe_submit_jobs = max(1, safe_submit_jobs)

        logger.info(
            "Using Slurm with safe limits - Array size: %d (max: %d), Submit jobs: %d (max: %d)",
            safe_array_size,
            max_array_size,
            safe_submit_jobs,
            max_submit_jobs,
        )

        executor = submitit.SlurmExecutor(folder=cfg.log_to)
        executor.update_parameters(
            time=int(cfg.n_hours * 60),  # Convert hours to minutes
            partition=cfg.slurm_partition,
            gpus_per_node=0,
            ntasks_per_node=1,
            cpus_per_task=8,
            mem_per_cpu="10gb",
            stderr_to_stdout=True,
            account=cfg.slurm_acct,
            array_parallelism=safe_array_size,
        )
    else:
        logger.info("Using DebugExecutor for local execution")
        executor = submitit.DebugExecutor(folder=cfg.log_to)
        safe_array_size = len(group_batches)
        safe_submit_jobs = len(group_batches)

    # Submit jobs in batches to respect Slurm limits
    all_jobs = []
    job_batches = list(btx.helpers.batched_idx(len(group_batches), safe_array_size))

    for batch_idx, (start, end) in enumerate(job_batches):
        current_batches = group_batches[start:end]

        # Check current job count and wait if needed (only for Slurm)
        if cfg.slurm_acct:
            current_jobs = btx.helpers.get_slurm_job_count()
            jobs_available = max(0, safe_submit_jobs - current_jobs)

            while jobs_available < len(current_batches):
                logger.info(
                    "Can only submit %d jobs but need %d. Waiting for jobs to complete...",
                    jobs_available,
                    len(current_batches),
                )
                time.sleep(60)  # Wait 1 minute
                current_jobs = btx.helpers.get_slurm_job_count()
                jobs_available = max(0, safe_submit_jobs - current_jobs)

        logger.info(
            "Submitting job batch %d/%d: jobs %d-%d",
            batch_idx + 1,
            len(job_batches),
            start,
            end - 1,
        )

        # Submit jobs for this batch
        with executor.batch():
            for group_start, group_end in current_batches:
                group_batch = all_group_basenames[group_start:group_end]
                job = executor.submit(worker_fn, cfg, group_batch)
                all_jobs.append(job)

        logger.info("Submitted job batch %d/%d", batch_idx + 1, len(job_batches))

    logger.info("Submitted %d total jobs. Waiting for results...", len(all_jobs))

    # Collect results and count annotations/errors
    all_annotations = []
    all_errors = []

    for job_idx, job in enumerate(all_jobs):
        try:
            results = job.result()
            for result in results:
                if isinstance(result, WorkerError):
                    all_errors.append(result)
                else:
                    all_annotations.append(result)
            logger.info("Job %d/%d completed", job_idx + 1, len(all_jobs))
        except Exception as e:
            logger.error("Job %d/%d failed: %s", job_idx + 1, len(all_jobs), e)

    # Report final statistics
    logger.info("=" * 60)
    logger.info("PROCESSING COMPLETE")
    logger.info("=" * 60)
    logger.info("Total annotations: %d", len(all_annotations))
    logger.info("Total errors: %d", len(all_errors))

    if all_errors:
        logger.info("\nError summary:")
        error_types = {}
        for error in all_errors:
            error_type = type(error).__name__
            error_types[error_type] = error_types.get(error_type, 0) + 1
        for error_type, count in error_types.items():
            logger.info("  %s: %d", error_type, count)

    # Check expected vs actual annotation count
    expected_count = sum(
        len(img_df.filter(pl.col("GroupImgBasename") == gb))
        for gb in all_group_basenames
    )
    logger.info("\nExpected annotations: %d", expected_count)
    logger.info("Actual annotations: %d", len(all_annotations))
    if expected_count != len(all_annotations) + len(all_errors):
        logger.warning(
            "Mismatch in annotation count! Missing: %d",
            expected_count - len(all_annotations) - len(all_errors),
        )

    if not all_annotations:
        return 1

    # Save annotations to disk
    output_file = cfg.dump_to / "annotations.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    logger.info("Saving annotations to %s", output_file)

    # Convert annotations to JSON format with trait polylines
    json_data = []

    for annotation in all_annotations:
        # Get base annotation data
        ann_dict = annotation.to_dict()

        # Get trait annotations for this beetle
        trait_row = trait_df.filter(
            (pl.col("GroupImgBasename") == annotation.group_img_basename)
            & (pl.col("BeetlePosition") == annotation.beetle_position)
        )

        # Add trait polylines if available
        if trait_row.is_empty():
            ann_dict["measurements"] = []
            json_data.append(ann_dict)
            continue

        measurements = []
        trait_data = trait_row.to_dicts()[0]

        # Process each trait type
        trait_types = {
            "coords_elytra_max_length": "elytra_max_length",
            "coords_basal_pronotum_width": "basal_pronotum_width",
            "coords_elytra_max_width": "elytra_max_width",
        }

        for coords_key, measurement_type in trait_types.items():
            if coords_key not in trait_data:
                continue

            coords = trait_data[coords_key]
            if not coords:
                continue

            for polyline in coords:
                if len(polyline) < 2:
                    continue

                if len(polyline) % 2 != 0:
                    logger.warning(
                        "Skipping polyline with odd length %d for %s in %s beetle %d",
                        len(polyline),
                        measurement_type,
                        annotation.group_img_basename,
                        annotation.beetle_position,
                    )
                    continue

                # Convert to individual image coordinates
                origin_x, origin_y = annotation.indiv_offset_px
                adjusted_polyline = []
                for i in range(0, len(polyline), 2):
                    adjusted_x = polyline[i] - origin_x
                    adjusted_y = polyline[i + 1] - origin_y
                    adjusted_polyline.extend([adjusted_x, adjusted_y])

                measurements.append({
                    "measurement_type": measurement_type,
                    "polyline_px": adjusted_polyline,
                })

        ann_dict["measurements"] = measurements
        json_data.append(ann_dict)

    # Save to JSON file
    with open(output_file, "w") as f:
        json.dump(json_data, f, indent=2)

    logger.info("Saved %d annotations to %s", len(json_data), output_file)

    return 0


if __name__ == "__main__":
    try:
        raise SystemExit(main(tyro.cli(Config)))
    except KeyboardInterrupt:
        print("Interrupted.")
        raise SystemExit(130)

>>>> scripts/merge_to_imagefolder.py
# src/btx/scripts/merge_to_imagefolder.py
import concurrent.futures
import dataclasses
import logging
import pathlib
import shutil

import beartype
import polars as pl
import tyro

from btx import helpers

log_format = "[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s"
logging.basicConfig(level=logging.INFO, format=log_format)


@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Config:
    bp_root: pathlib.Path = pathlib.Path("./data/beetlepalooza")
    """Where you dumped data when using download_beetlepalooza.py."""
    hi_root: pathlib.Path = pathlib.Path("./data/hawaii")
    """Where you dumped data when using download_hawaii.py."""
    br_root: pathlib.Path = pathlib.Path("./data/biorepo")
    """Where you dumped data when using download_biorepo.py."""
    dump_to: pathlib.Path = pathlib.Path("./data/imagefolder")
    """Where to write the new image directories."""
    n_threads: int = 16
    """Number of concurrent threads for copying files on disk."""
    job_size: int = 256
    """Number of images to copy per job."""


@beartype.beartype
def _move_bp(cfg: Config, start: int, end: int):
    bp_df = pl.read_csv(cfg.bp_root / "individual_specimens.csv")

    for (img_fpath,) in (
        bp_df.select("individualImageFilePath").slice(start, end - start).iter_rows()
    ):
        src_fpath = cfg.bp_root / img_fpath
        img_fname = pathlib.Path(img_fpath).name
        dst_fpath = cfg.dump_to / "beetlepalooza" / img_fname

        if not src_fpath.exists():
            continue

        if dst_fpath.exists():
            continue

        shutil.copy2(src_fpath, dst_fpath)


@beartype.beartype
def _move_hi(cfg: Config, start: int, end: int):
    hi_df = pl.read_csv(cfg.hi_root / "images_metadata.csv")
    for (img_fpath,) in (
        hi_df.select("individualImageFilePath").slice(start, end - start).iter_rows()
    ):
        src_fpath = cfg.hi_root / img_fpath
        img_fname = pathlib.Path(img_fpath).name
        dst_fpath = cfg.dump_to / "hawaii" / img_fname

        if not src_fpath.exists():
            continue

        if dst_fpath.exists():
            continue

        shutil.copy2(src_fpath, dst_fpath)
    pass


@beartype.beartype
def _move_br(cfg: Config, i: int):
    pq_fpath = cfg.br_root / "data" / f"train-{i:05}-of-00029.parquet"
    if not pq_fpath.exists():
        return

    br_df = pl.read_parquet(pq_fpath)

    for (file_dict,) in br_df.select("file_path").iter_rows():
        img_bytes = file_dict["bytes"]
        img_fname = pathlib.Path(file_dict["path"])
        img_fpath = cfg.dump_to / "biorepo" / f"{img_fname.stem}_{i}{img_fname.suffix}"

        if img_fpath.exists():
            continue

        with open(img_fpath, "wb") as fd:
            fd.write(img_bytes)


@beartype.beartype
def main(cfg: Config):
    """
    Converts all the imageomics beetle datasets into one merged root/class/example.png format for use with ImageFolder dataloaders.
    """
    logger = logging.getLogger("merge")

    (cfg.dump_to / "beetlepalooza").mkdir(exist_ok=True, parents=True)
    (cfg.dump_to / "hawaii").mkdir(exist_ok=True, parents=True)
    (cfg.dump_to / "biorepo").mkdir(exist_ok=True, parents=True)

    bp_df = pl.read_csv(cfg.bp_root / "individual_specimens.csv")
    hi_df = pl.read_csv(cfg.hi_root / "images_metadata.csv")

    with concurrent.futures.ThreadPoolExecutor(max_workers=cfg.n_threads) as pool:
        futs = []

        # BeetlePalooza
        futs.extend([
            pool.submit(_move_bp, cfg, start, end)
            for start, end in helpers.batched_idx(bp_df.height, cfg.job_size)
        ])

        # Hawaii
        futs.extend([
            pool.submit(_move_hi, cfg, start, end)
            for start, end in helpers.batched_idx(hi_df.height, cfg.job_size)
        ])

        # BioRepo
        futs.extend([pool.submit(_move_br, cfg, i) for i in range(29)])

        for fut in helpers.progress(
            concurrent.futures.as_completed(futs), total=len(futs), desc="copying"
        ):
            if err := fut.exception():
                logger.warning("Exception: %s", err)


if __name__ == "__main__":
    try:
        raise SystemExit(main(tyro.cli(Config)))
    except KeyboardInterrupt:
        print("Interrupted.")
        raise SystemExit(130)

